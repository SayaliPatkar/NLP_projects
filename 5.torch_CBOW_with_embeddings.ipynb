{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1cf35865a70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two words before i th word and two words after i th word form a context\n",
    "CONTEXT_SIZE = 2\n",
    "\n",
    "# 10 dimensional embeddings, embedding vector has size [n,10], n = number of words in vocabulary\n",
    "EMBEDDING_DIM = 10\n",
    "\n",
    "# Macbeth\n",
    "test_para = \"\"\"The raven himself is hoarse,\n",
    "That croaks the fatal entrance of Duncan\n",
    "Under my battlements. Come, you spirits\n",
    "That tend on mortal thoughts, unsex me here,\n",
    "And fill me from the crown to the toe top-full\n",
    "Of direst cruelty! make thick my blood;\n",
    "Stop up the access and passage to remorse,\n",
    "That no compunctious visitings of nature\n",
    "Shake my fell purpose, nor keep peace between\n",
    "The effect and it! Come to my woman’s breasts,\n",
    "And take my milk for gall, you murdering ministers,\n",
    "Wherever in your sightless substances\n",
    "You wait on nature’s mischief! Come, thick night,\n",
    "And pall thee in the dunnest smoke of hell,\n",
    "That my keen knife see not the wound it makes,\n",
    "Nor heaven peep through the blanket of the dark,\n",
    "To cry ‘Hold, hold!’\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length :::  98\n",
      "Generated CBOW :::  [(['The', 'raven', 'is', 'hoarse,'], 'himself'), (['raven', 'himself', 'hoarse,', 'That'], 'is'), (['himself', 'is', 'That', 'croaks'], 'hoarse,'), (['is', 'hoarse,', 'croaks', 'the'], 'That'), (['hoarse,', 'That', 'the', 'fatal'], 'croaks')]\n"
     ]
    }
   ],
   "source": [
    "vocab = set(test_para)\n",
    "vocab_size = len(vocab)\n",
    "print(\"Vocabulary length ::: \", vocab_size)\n",
    "\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "data = []\n",
    "for i in range(2, len(test_para) - 2):\n",
    "    context = [test_para[i - 2], test_para[i - 1],\n",
    "               test_para[i + 1], test_para[i + 2]]\n",
    "    target = test_para[i]\n",
    "    data.append((context, target))\n",
    "print(\"Generated CBOW ::: \",data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\VENVS\\torch_venv\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[574.643773317337, 570.9957427978516, 567.3815424442291, 563.7986721992493, 560.243744134903, 556.715674161911, 553.2099783420563, 549.7271420955658, 546.2651727199554, 542.820720911026, 539.3921296596527, 535.9783999919891, 532.5780999660492, 529.1924240589142, 525.8173489570618, 522.4510202407837, 519.0959916114807, 515.7501153945923, 512.4106996059418, 509.07572984695435, 505.7439651489258, 502.4139461517334, 499.0902771949768, 495.77408957481384, 492.46336555480957, 489.16151547431946, 485.86507868766785, 482.5750743150711, 479.2907748222351, 476.0074745416641, 472.7292813062668, 469.4566503763199, 466.185830950737, 462.91646015644073, 459.6520085334778, 456.3902645111084, 453.1323436498642, 449.87439036369324, 446.61417031288147, 443.35293793678284, 440.0900717973709, 436.82505917549133, 433.5539928674698, 430.27351117134094, 426.98337280750275, 423.6858986020088, 420.3775392770767, 417.06152683496475, 413.7356404662132, 410.39505565166473, 407.0431424379349, 403.68037378787994, 400.30485409498215, 396.91542172431946, 393.51554495096207, 390.10354870557785, 386.67778861522675, 383.23539328575134, 379.77820897102356, 376.3042925596237, 372.821555018425, 369.32148763537407, 365.81049957871437, 362.28054147958755, 358.7384516596794, 355.1814813911915, 351.610893458128, 348.0265258550644, 344.43300825357437, 340.8251349925995, 337.2047993540764, 333.5709044635296, 329.9262553155422, 326.2675988674164, 322.5955613255501, 318.9169511497021, 315.2213788330555, 311.5204034149647, 307.8141432404518, 304.102001786232, 300.3838749527931, 296.6634067296982, 292.93299347162247, 289.20120164752007, 285.4637454152107, 281.72594398260117, 277.989600867033, 274.25270345807076, 270.5158240199089, 266.7861196696758, 263.0537519752979, 259.3325493335724, 255.6116283237934, 251.89907440543175, 248.19261325895786, 244.49834954738617, 240.8158669322729, 237.141696408391, 233.48674182593822, 229.84083883464336]\n"
     ]
    }
   ],
   "source": [
    "class CBOW(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear((context_size**2) * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = functional.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = functional.log_softmax(out, dim=1)\n",
    "        return log_probs\n",
    "\n",
    "\n",
    "def make_context_vector(context, word_to_ix):\n",
    "    idxs = [word_to_ix[w] for w in context]\n",
    "    return torch.tensor(idxs, dtype=torch.long)    \n",
    "    \n",
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = CBOW(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for context, target in data:\n",
    "\n",
    "        # Converting each owrd in 1*10 sized tensor tensor\n",
    "        context_idxs = torch.tensor(make_context_vector(context, word_to_ix), dtype=torch.long)\n",
    "\n",
    "        # Recall that torch *accumulates* gradients. Before passing in a\n",
    "        # new instance, you need to zero out the gradients from the old\n",
    "        # instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Run the forward pass, getting log probabilities over next words\n",
    "        log_probs = model(context_idxs)\n",
    "\n",
    "        # Compute your loss function. (Again, Torch wants the target word wrapped in a tensor)\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "\n",
    "        # Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "print(losses)  # The loss decreased every iteration over the training data!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_venv",
   "language": "python",
   "name": "torch_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
